# TAMS Rust Implementation

A high-performance Time-addressable Media Store (TAMS) API server implementation in Rust.

## Overview

This project implements the [TAMS API specification v6.0](https://github.com/bbc/tams) from the BBC, providing a REST API for managing time-addressable media content with support for sources, flows, segments, and webhook notifications.

## Features

### âœ… Implemented

- **Core Data Models**: Complete TAMS data structures (Sources, Flows, Segments, Media Objects)
- **Database Layer**: SQLite-based persistence with connection pooling
- **Media Storage**: Local filesystem storage with presigned URL generation
- **Configuration Management**: TOML-based configuration with comprehensive settings
- **Error Handling**: Comprehensive error types with proper HTTP status mapping
- **Authentication**: JWT Bearer token and Basic Auth support
- **Webhook System**: Async webhook notifications for all TAMS events
- **Time Utilities**: Robust TAMS timestamp parsing and validation
- **HTTP Handlers**: Complete REST API endpoint implementations
- **Logging**: Structured logging with configurable levels and formats

### ðŸ”§ Core Architecture

- **Async/Await**: Built on Tokio for high-performance async I/O
- **Type Safety**: Leverages Rust's type system for compile-time guarantees
- **Memory Efficient**: Zero-copy where possible, minimal allocations
- **Thread Safe**: Arc/Mutex patterns for safe concurrent access
- **Error Propagation**: Result-based error handling throughout

## API Endpoints

The implementation provides all TAMS v6.0 REST endpoints:

### Core Endpoints

- `GET /` - Root endpoint with API information
- `GET /service` - Service capabilities and information

### Sources Management

- `GET /sources` - List sources with pagination
- `POST /sources` - Create new source
- `GET /sources/{sourceId}` - Get specific source
- `PUT /sources/{sourceId}` - Update source
- `DELETE /sources/{sourceId}` - Delete source

### Flows Management

- `GET /flows` - List flows with pagination
- `POST /flows` - Create new flow
- `GET /flows/{flowId}` - Get specific flow
- `PUT /flows/{flowId}` - Update flow
- `DELETE /flows/{flowId}` - Delete flow

### Flow Segments

- `GET /flows/{flowId}/segments` - List flow segments
- `POST /flows/{flowId}/segments` - Add segments to flow
- `DELETE /flows/{flowId}/segments` - Delete segments by timerange

### Storage Management

- `GET /flows/{flowId}/storage` - Get presigned upload URLs

### Media Objects

- `GET /objects/{objectId}` - Get media object metadata
- `HEAD /objects/{objectId}` - Check media object existence

### Webhooks

- `GET /service/webhooks` - List registered webhooks
- `POST /service/webhooks` - Register new webhook
- `DELETE /service/webhooks/{url}` - Unregister webhook

### Flow Deletion Requests

- `GET /flow-delete-requests` - List deletion requests
- `POST /flow-delete-requests` - Create deletion request
- `GET /flow-delete-requests/{id}` - Get deletion request status

## Configuration

The server is configured via `config.toml`:

```toml
[server]
host = "127.0.0.1"
port = 8080
workers = 4

[database]
url = "sqlite:./tams.db"
max_connections = 10
connection_timeout_seconds = 30

[media_storage]
base_path = "./media_storage"
max_file_size = 104857600  # 100MB
temp_path = "./temp_uploads"

[service]
name = "TAMS Rust Implementation"
description = "Time-addressable Media Store API server in Rust"
version = "6.0"
media_store_type = "http_object_store"
public_url_base = "http://localhost:8080/media"

[auth]
require_auth = false
jwt_secret = "your-256-bit-secret-key-change-this-in-production"
basic_auth_username = "admin"
basic_auth_password = "password"

[cors]
allowed_origins = ["*"]
allowed_methods = ["GET", "POST", "PUT", "DELETE", "HEAD", "OPTIONS"]
allowed_headers = ["*"]

[logging]
level = "info"
format = "compact"  # "compact", "pretty", or "json"

[pagination]
default_limit = 50
max_limit = 1000

[cleanup]
temp_file_retention_hours = 24
orphaned_object_retention_days = 7
```

## Building and Running

### Prerequisites

- Rust 1.70+
- SQLite 3.35+

### Create the database

```
Create the data directory (matching your config.toml change)
mkdir -p data

# Create the database and tables
sqlite3 data/tams.db < create_db.sql
```

### Build

```bash
cargo build --release
```

### Run

```bash
# With default config.toml
cargo run

# Or run the binary directly
./target/release/tams-rust
```

### Development

```bash
# Run with debug logging
RUST_LOG=debug cargo run

# Run tests
cargo test

# Format code
cargo fmt

# Lint
cargo clippy
```

## Project Structure

```
src/
â”œâ”€â”€ main.rs           # Application entry point and routing
â”œâ”€â”€ config.rs         # Configuration loading and structures
â”œâ”€â”€ models.rs         # TAMS data models and types
â”œâ”€â”€ database.rs       # Database operations and migrations
â”œâ”€â”€ storage.rs        # Media storage abstraction
â”œâ”€â”€ handlers.rs       # HTTP request handlers
â”œâ”€â”€ auth.rs           # Authentication middleware
â”œâ”€â”€ webhooks.rs       # Webhook notification system
â”œâ”€â”€ time_utils.rs     # Time parsing and validation utilities
â””â”€â”€ error.rs          # Error types and HTTP mapping

config.toml           # Server configuration
Cargo.toml           # Rust dependencies and metadata
```

## Data Models

### Core Types

- **Source**: Media source with format and metadata
- **Flow**: Media flow with encoding parameters and timerange
- **FlowSegment**: Time-bounded segment within a flow
- **MediaObject**: Actual media file with references
- **TimeRange**: Start/end timestamps in TAMS format (`seconds:nanoseconds`)

### Time Format

TAMS uses a specific timestamp format: `{unix_seconds}:{nanoseconds}`

Examples:

- `1609459200:000000000` (2021-01-01 00:00:00 UTC)
- `1609459200:500000000` (2021-01-01 00:00:00.5 UTC)

## Webhook Events

The system sends webhook notifications for:

- `source.created` - New source created
- `source.updated` - Source modified
- `source.deleted` - Source removed
- `flow.created` - New flow created
- `flow.updated` - Flow modified
- `flow.deleted` - Flow removed
- `segments.added` - Segments added to flow
- `segments.deleted` - Segments removed from flow

## Authentication

### JWT Bearer Tokens

```bash
curl -H "Authorization: Bearer <token>" http://localhost:8080/sources
```

### Basic Auth

```bash
curl -u admin:password http://localhost:8080/sources
```

## Storage

Media files are stored in a local directory with a two-level structure for performance:

```
media_storage/
â”œâ”€â”€ ab/
â”‚   â””â”€â”€ ab123...def
â”œâ”€â”€ cd/
â”‚   â””â”€â”€ cd456...789
â””â”€â”€ ...
```

Upload URLs are presigned and expire after 1 hour by default.

## Performance

- **Async I/O**: All operations are non-blocking
- **Connection Pooling**: Database connections are pooled and reused
- **Streaming**: Large file operations use streaming where possible
- **Memory Efficient**: Minimal allocations and zero-copy operations
- **Concurrent**: Handles multiple requests concurrently

## Logging

Structured logging with multiple output formats:

```bash
# JSON format
TAMS_LOG_FORMAT=json cargo run

# Pretty format for development
TAMS_LOG_FORMAT=pretty cargo run

# Compact format (default)
cargo run
```

## Current Status

### Completed âœ…

- All core modules implemented
- Database schema and operations
- HTTP routing and handlers
- Authentication middleware
- Webhook system
- Media storage abstraction
- Configuration management
- Error handling
- Time utilities
- Logging setup

### Next Steps ðŸ”§

1. **Fix Compilation Issues**: Resolve remaining type mismatches and method signatures
2. **Database Query Preparation**: Run `cargo sqlx prepare` for offline builds
3. **Integration Testing**: Add end-to-end API tests
4. **Media Upload/Download**: Implement actual file upload/download endpoints
5. **Background Tasks**: Implement deletion request processing
6. **Monitoring**: Add metrics and health checks
7. **Docker**: Add Dockerfile and docker-compose

### Known Issues

- Some database method signatures need alignment with handlers
- SQLx compile-time checks require database setup for offline builds
- Media upload/download endpoints need implementation
- Flow deletion background processing is TODO

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Run `cargo fmt` and `cargo clippy`
6. Submit a pull request

## License

Apache 2.0 License

## References

- [TAMS API Specification](https://github.com/bbc/tams)
- [BBC Technical Standards](https://www.bbc.co.uk/makerbox/)
- [Rust Async Book](https://rust-lang.github.io/async-book/)
- [Axum Documentation](https://docs.rs/axum/)
